{"id":"USgKoryE83j5SszZjyr68sh7DjLn4j6MWUagcNjQES7kQ1n2HXebXN4bJpBn8stf6LqSMrbny1unc4R1hi6qmf","title":"top scoring links : golang","displayTitle":"Reddit - Go","url":"https://www.reddit.com/r/golang/top/.rss?sort=top&t=day&limit=6","feedLink":"https://www.reddit.com/r/golang/top/?sort=top&t=day&limit=6","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":6,"items":[{"title":"Cheating the Reaper in Go · mcyoung","url":"https://mcyoung.xyz/2025/04/21/go-arenas/","date":1745293012,"author":"/u/FoxInTheRedBox","guid":400,"unread":true,"content":"<p>Even though I am a C++ programmer at heart, Go fascinates me for none of the reasons you think. Go has made several interesting design decisions:</p><ol><li><p>It has virtually no Undefined Behavior.</p></li><li><p>It has very simple GC semantics that they’re mostly stuck with due to design decisions in the surface language.</p></li></ol><p>These things mean that despite Go having a GC, it’s possible to do manual memory management in pure Go and in cooperation with the GC (although without any help from the  package). To demonstrate this, we will be building an untyped, garbage-collected arena abstraction in Go which relies on several GC implementation details.</p><p>I would never play this kind of game in Rust or C++, because LLVM is extremely intelligent and able to find all kinds of ways to break you over the course of frequent compiler upgrades. On the other hand, although Go does not promise any compatibility across versions for code that imports , in practice, two forces work against Go doing this:</p><ol><li><p>Go prioritizes not breaking the ecosystem; this allows to assume that <a href=\"https://www.hyrumslaw.com/\">Hyrum’s Law</a> will protect certain observable behaviors of the runtime, from which we may infer what can or cannot break easily.</p></li></ol><p>This is in contrast to a high-performance native compiler like LLVM, which has a carefully defined boundary around all UB, allowing them to arbitrarily break programs that cross it (mostly) without fear of breaking the ecosystem.</p><p>So, let’s dive in and cheat death.</p><p>Our goal is to build an , which is a data structure for efficient allocation of memory that has the same lifetime. This reduces pressure on the general-purpose allocator by only requesting memory in large chunks and then freeing it all at once.</p><p>For a comparison in Go, consider the following program:</p><div><figure><pre><code data-lang=\"go\"></code></pre></figure></div><p>This program will print successive powers of 2: this is because  is implemented approximately like so:</p><div><figure><pre><code data-lang=\"go\"></code></pre></figure></div><p>For appending small pieces,  is only called  times, a big improvement over calling it for every call to . Virtually every programming language’s dynamic array abstraction makes this optimization.</p><p>An arena generalizes this concept, but instead of resizing exponentially, it allocates  blocks and vends pointers into them. The interface we want to conform to is as follows:</p><div><figure><pre><code data-lang=\"go\"></code></pre></figure></div><p>In go a size and and an alignment, out comes a pointer fresh memory with that layout. Go does not have user-visible uninitialized memory, so we additionally require that the returned region be zeroed. We also require that  be a power of two.</p><p>We can give this a type-safe interface by writing a generic  function:</p><div><figure><pre><code data-lang=\"go\"></code></pre></figure></div><p>This all feels very fine and dandy to anyone used to hurting themselves with  or  in C++, but there is a small problem. What happens when we allocate pointer-typed memory into this allocator?</p><div><figure><pre><code data-lang=\"go\"></code></pre></figure></div><p> takes a size and an alignment, which is sufficient to describe the  of any type. For example, on 64-bit systems,  and  have the same layout: 8 bytes of size, and 8 bytes of alignment.</p><p>However, the Go GC (and all garbage collectors, generally) require one additional piece of information, which is somewhere between the layout of a value (how it is placed in memory) and the type of a value (rich information on its structure). To understand this, we need a brief overview on what a GC does.</p><blockquote><p>For a complete overview on how to build a simple GC, take a look at a toy GC I designed some time ago: <a href=\"https://mcyoung.xyz/2022/06/07/alkyne-gc/\">The Alkyne GC</a>.</p></blockquote><p>A garbage collector’s responsibility is to maintain a memory allocator and an accounting of:</p><ol><li>What memory has been allocated.</li><li>Whether that memory is still in use.</li></ol><p>Memory that is not in use can be reclaimed and marked as unallocated, for re-use.</p><p>The most popular way to accomplish this is via a “mark and sweep” architecture. The GC will periodically walk the entire object graph of the program from certain pre-determined ; anything it finds is “marked” as alive. After a mark is complete, all other memory is “swept”, which means to mark it is unallocated for future re-use, or to return it to the OS, in the case of significant surplus.</p><p>The roots are typically entities that are actively being manipulated by the program. In the case of Go, this is anything currently on the stack of some G, or anything in a global (of which there is a compile-time-known set).</p><p>The marking phase begins with , which looks at the stack of each G and locates any pointers contained therein. The Go compiler generates metadata for each function that specifies which stack slots in a function’s frame contain pointers. All of these pointers are live by definition.</p><p>These pointers are placed into a queue, and each pointer is traced to its allocation on the heap. If the GC does not know anything about a particular address, it is discarded as foreign memory that does not need to be marked. If it does, each pointer in that allocation is pushed onto the queue if it has not already been marked as alive. The process continues until the queue is empty.</p><p>The critical step here is to take the address of some allocation, and convert it into all of the pointer values within. Go has precise garbage collection, which means that it only treats things declared as pointers in the surface language as pointers: an integer that happens to look like an address will not result in sweeping. This results in more efficient memory usage, but trades off some more complexity in the GC.</p><p>For example, the types , , ,  all contain at least one pointer, while , , <code>struct {X bool; F uintptr}</code> do not. The latter are called  types.</p><p>Go enhances the layout of a type into a  by adding a bitset that specifies which pointer-aligned, pointer-sized words of the type’s memory region contain a pointer. These are called the . For example, here are the shapes of a few Go types on a 64-bit system.</p><table><thead><tr></tr></thead><tbody><tr></tr></tbody></table><p>In the Go GC, each allocation is tagged with its shape (this is done in a variety of ways in the GC, either through an explicit header on the allocation, itself (a “malloc header”), a runtime type stored in the allocation’s , or another mechanism). When scanning a value, it uses this information to determine where the pointers to scan through are.</p><p>The most obvious problem with our  type is that it does not discriminate shapes, so it cannot allocate memory that contains pointers: the GC will not be able to find the pointers, and will free them prematurely!</p><p>In our example where we allocated an  in our custom allocator, we wind up with a  on the stack. You would think that Go would simply trace through the first  to find an  and mark it as being alive, but that is not what happens! Go instead finds a pointer into some chunk that the custom allocator grabbed from the heap, which is missing the pointer bits of its shape!</p><p>Why does go not look at the type of the pointer it steps through? Two reasons.</p><ol><li><p>All pointers in Go are untyped from the runtime’s perspective; every  gets erased into an . This allows much of the Go runtime to be “generic” without using actual generics.</p></li><li><p>Pointee metadata can be aggregated, so that each pointer to an object does not have to remember its type at runtime.</p></li></ol><p>The end result for us is that we can’t put pointers on the arena. This makes our  API unsafe, especially since Go does not provide a standard constraint for marking generic parameters as pointer-free: unsurprisingly, the don’t expect most users to care about such a detail.</p><p>It  possible to deduce the pointer bits of a type using reflection, but that’s very slow, and the whole point of using arenas is to go fast. As we design our arena, though, it will become clear that there is a safe way to have pointers on it.</p><p>Now that we have a pretty good understanding about what the Go GC is doing, we can go about designing a fast arena structure.</p><p>The ideal case is that a call to  is very fast: just offsetting a pointer in the common case. One assumption we can make off the bat is that all memory can be forced to have maximum alignment: most objects are a pointer or larger, and Go does have a maximum alignment for ordinary user types, so we can just ignore the  parameter and always align to say, 8 bytes. This means that the pointer to the next unallocated chunk will always be well-aligned. Thus, we might come up with a structure like this one:</p><div><figure><pre><code data-lang=\"go\"></code></pre></figure></div><p>How fast is this really? Here’s a simple benchmark for it.</p><div><figure><pre><code data-lang=\"go\"></code></pre></figure></div><p>The focus of this benchmark is to measure the cost of allocating many objects of the same size. The number of times the  loop will execute is unknown, and determined by the benchmarking framework to try to reduce statistical anomaly. This means that if we instead just benchmark a single allocation, the result will be  sensitive to the number of runs.</p><p>We also use  to get a throughput measurement on the benchmark. This is a bit easier to interpret than the gross , the benchmark would otherwise produce. It tells us how much memory each allocator can allocate per unit time.</p><p>We want to compare against , but just writing  will get optimized out, since the resulting pointer does not escape. Writing it to a global is sufficient to convince Go that it escapes.</p><p>Here’s the results, abbreviated to show only the bytes per second. All benchmarks were performed on my AMD Ryzen Threadripper 3960X. Larger is better.</p><div><figure><pre><code data-lang=\"console\"></code></pre></figure></div><p>This is quite nice, and certainly worth pursuing! The performance increase seems to scale up with the amount of memory allocated, for a 2x-4x improvement across different cases.</p><p>Now we need to contend with the fact that our implementation is completely broken if we want to have pointers in it.</p><p>In , when we assign a freshly-allocated chunk, we overwrite , which means the GC can reclaim it. But this is fine: as long as pointers into that arena chunk are alive, the GC will not free it, independent of the arena. So it seems like we don’t need to worry about it?</p><p>However, the whole point of an arena is to allocate lots of memory that has the same lifetime. This is common for graph data structures, such as an AST or a compiler IR, which performs a lot of work that allocates a lot and then throws the result away.</p><p>We are not allowed to put pointers in the arena, because they would disappear from the view of the GC and become freed too soon. But, if a pointer wants to go on an arena, it necessarily outlive the whole arena, since it outlives part of the arena, and the arena is meant to have the same lifetime.</p><p>In particular, if we could make it so that holding any pointer returned by  prevents the  from being swept by the GC, the arena can safely contain pointers into itself! Consider this:</p><ol><li><p>We have a pointer . It is allocated on some arena .</p></li><li><p>The GC sees our pointer (as a type-erased ) and marks its allocation as live.</p></li><li><p>Somehow, the GC also marks  as alive as a consequence.</p></li><li><p>Somehow, the GC then marks every chunk  has allocated as alive.</p></li><li><p>Therefore he chunk that  points to is also alive, so  does not need to be marked directly, and will not be freed early.</p></li></ol><p>The step (3) is crucial. By forcing the whole arena to be marked, any pointers stored in the arena into itself will be kept alive automatically, without the GC needing to know how to scan for them.</p><p>So, even though  is still going to result in a use-after-free, <code>*New[*int](a) = New[int](a)</code> would not! This small improvement does not make arenas themselves safe, but a data structure with an internal arena can be completely safe, so long as the only pointers that go into the arena are from the arena itself.</p><p>How can we make this work? The easy part is (4), which we can implement by adding a  to the arena, and sticking every pointer we allocate into it.</p><div><figure><pre><code data-lang=\"go\"></code></pre></figure></div><p>The cost of the  is amortized: to allocate  bytes, we wind up allocating an additional  times. But what does this do to our benchmarks?</p><div><figure><pre><code data-lang=\"console\"></code></pre></figure></div><p>Seems pretty much the same, which is a good sign.</p><p>Now that the arena does not discard any allocated memory, we can focus on condition (3): making it so that if any pointer returned by  is alive, then so is the whole arena.</p><p>Here we can make use of an important property of how Go’s GC works: any pointer into an allocation will keep it alive, as well as <em>anything reachable from that pointer</em>. But the chunks we’re allocating are s, which will not be scanned. If there could  be a single pointer in this slice that was scanned, we would be able to stick the pointer  there, and so when anything that  returns is scanned, it would cause  to be marked as alive.</p><p>So far, we have been allocating  using , but we would actually like to allocate <code>struct { A [N]uintptr; P unsafe.Pointer }</code>, where  is some dynamic value.</p><p>In its infintie wisdom, the Go standard library actually gives us a dedicated mechanism to do this: . This can be used to construct arbitrary anonymous  types at runtime, which we can then allocate on the heap.</p><p>So, instead of calling , we might call this function:</p><div><figure><pre><code data-lang=\"go\"></code></pre></figure></div><p>This appears to have a minor but noticeable effect on performance.</p><div><figure><pre><code data-lang=\"console\"></code></pre></figure></div><p>Looking back at , the end of this function has a branch:</p><div><figure><pre><code data-lang=\"go\"></code></pre></figure></div><p>This is the absolute hottest part of allocation, since it is executed every time we call this function. The branch is a bit unfortunate, but it’s necessary, as noted by the comment.</p><p>In C++, if we have an array of  with  elements in it, and  is a pointer to the start of the array,  is a valid pointer, even though it can’t be dereferenced; it points “one past the end” of the array. This is a useful construction, since, for example, you can use it to eliminate a loop induction variable:</p><div><figure><pre><code data-lang=\"c++\"></code></pre></figure></div><p>Go, however, gets very upset if you do this, because it confuses the garbage collector. The GC can’t tell the difference between a one-past-the-end pointer for allocation A, and for the start of allocation B immediately after it. At best this causes memory to stay alive for longer, and at worst it triggers safety interlocks in the GC. The GC will panic if it happens to scan a pointer for an address that it knows has been freed.</p><p>But in our code above, every chunk now has an extra element at the very end that is not used for allocation, so we  have a pointer that  one-past-the-end of the  that we are vending memory from.</p><p>The updated allocation function would look like this:</p><div><figure><pre><code data-lang=\"go\"></code></pre></figure></div><p>Notably, we do not replace  with an end pointer, because of the  comparison. We can’t actually avoid the subtraction  because we would have to do it to make this comparison work if we got rid of .</p><p>So how much better is this?</p><div><figure><pre><code data-lang=\"console\"></code></pre></figure></div><p>Remarkably, not very! This is an improvement on the order of magnitude of one or two percentage points. This is because the branch we deleted is extremely predictable.</p><p>Turns out there’s a bigger improvement we can make.</p><p>Here’s the assembly Go generated for this function, heavily abridged, and annotated with the corresponding Go source code.</p><div><figure><pre><code data-lang=\"llvm\"></code></pre></figure></div><p>There’s a lot going on in this function, but most of it is a mix of Go not being great at register allocation, and lots of .</p><p>A write barrier is a mechanism for synchronizing ordinary user code with the GC. Go generates code for one any time a non-pointer-free type is stored. For example, writing to a , , or  requires a write barrier.</p><p>Write barriers are implemented as follows:</p><ol><li><p> is checked, which determines whether the write barrier is necessary, which is only when the GC is in the mark phase. Otherwise the branch is taken to skip the write barrier.</p></li><li><p>A call to one of the  functions happens.  is the number of pointers that the GC needs to be informed of.</p></li><li><p>This function calls , which returns a buffer onto which pointers the GC needs to now trace through should be written to.</p></li><li><p>The actual store happens.</p></li></ol><p>A write barrier is required for a case like the following. Consider the following code.</p><div><figure><pre><code data-lang=\"go\"></code></pre></figure></div><p>This function will call  to allocate eight bytes of memory. The resulting pointer will be returned in . This function then stores  into  and returns. If we Godbolt this function, we’ll find that it does, in fact, generate a write barrier:</p><div><figure><pre><code data-lang=\"llvm\"></code></pre></figure></div><p>Note that two pointers get written: the pointer returned by , and the old value of . This ensures that regardless of where in this function the GC happens to be scanning through , it sees both values during the mark phase.</p><p>Now, this isn’t necessary if the relevant pointers are already reachable in some other way… which is exactly the case in our arena (thanks to the  slice). So the write barrier in the fast path is redundant.</p><p>But, how do we get rid of it? There is a , but that’s not allowed outside of a list of packages allowlisted in the compiler. It also doens’t disable write barriers; it simply generates a diagnostic if any are emitted.</p><p>But remember, write barriers only occur when storing pointer-typed memory… so we can just replace  with .</p><div><figure><pre><code data-lang=\"go\"></code></pre></figure></div><p> hates this, because it doesn’t know that we’re smarter than it is. Does This make the code faster? To make it a little bit more realistic, I’ve written a separate variant of the benchmarks that hammers the GC really hard in a separate G:</p><div><figure><pre><code data-lang=\"go\"></code></pre></figure></div><p>The result indicates that this is a worthwhile optimization for churn-heavy contexts. Performance is much worse overall, but that’s because the GC is pre-empting everyone. The improvement seems to be on the order of 20% for very small allocations.</p><div><figure><pre><code data-lang=\"console\">Before\nAfter\n</code></pre></figure></div><p>Go does not offer an easy mechanism to “reallocate” an allocation, as with  in C. This is because it has no mechanism for freeing pointers explicitly, which is necessary for a reallocation abstraction.</p><p>But we already don’t care about safety, so we can offer reallocation on our arena. Now, the reallocation we can offer is quite primitive: if a chunk happens to be the most recent one allocated, we can grow it. Otherwise we just allocate a new chunk and don’t free the old one.</p><p>This makes it possible to implement “arena slices” that can be constructed by appending, which will not trigger reallocation on slice growth as long as nothing else gets put on the arena.</p><p> would look something like this:</p><div><figure><pre><code data-lang=\"go\"></code></pre></figure></div><p>Then, whenever we append to our arena slice, we can call  to grow it. However, this does not work if the slice’s base pointer is not the original address returned by  or . It is an exercise for the reader to:</p><ol><li><p>Implement a  type that uses an arena for allocation.</p></li><li><p>Make this work for any value of  within the most recent allocation, not just the base offset. This requires extra book-keeping.</p></li></ol><p>Here is the entirety of the code that we have developed, not including the reallocation function above.</p><div><figure><pre><code data-lang=\"go\"></code></pre></figure></div><p>There are other optimizations that we could make here that I haven’t discussed. For example, arenas could be re-used; once an arena is done, it could be “reset” and placed into a . This arena would not need to go into the GC to request new chunks, re-using the ones previously allocated (and potentially saving on the cost of zeroing memory over and over again).</p><p>I did say that this relies very heavily on Go’s internal implementation details. Whats the odds that they get broken in the future? Well, the requirement that allocations know their shape is forced by the existence of , and the requirement that a pointer into any part of an allocation keeps the whole thing alive essentially comes from slices being both sliceable and mutable; once a slice escapes to the heap (and thus multiple goroutines) coordinating copies for shrinking a slice would require much more complexity than the current write barrier implementation.</p><p>And in my opinion, it’s pretty safe to say that Hyrum’s Law has us covered here. ;)</p>","contentLength":19102,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1k4wv4o/cheating_the_reaper_in_go_mcyoung/"},{"title":"Single method interfaces vs functions","url":"https://www.reddit.com/r/golang/comments/1k4u69x/single_method_interfaces_vs_functions/","date":1745284646,"author":"/u/RomanaOswin","guid":402,"unread":true,"content":"<p>I know this has been asked before and it's fairly subjective, but single method interfaces vs functions. Which would you choose when, and why? Both seemingly accomplish the exact same thing with minor tradeoffs.</p><p>In this case, I'm looking at this specifically in defining the capabilities provided in a domain-driven design. For example:</p><p><code>go type SesssionCreator interface { CreateSession(Session) error } type SessionReader interface { ReadSession(id string) (Session, error) } </code></p><p><code>go type ( CreateSessionFunc(Session) error ReadSessionFunc(id string) (Session, error) ) </code></p><p>And, then in some consumer, e.g., an HTTP handler:</p><p>```go func PostSession(store identity.SessionCreator) HttpHandlerFunc { return func(req Request) { store.CreateSession(s) } }</p><p>func PostSession(createSession identity.CreateSessionFunc) HttpHandlerFunc { return func(req Request) { createSession(s) } } ```</p><p>I think in simple examples like this, functions seem simpler than interfaces, the test will be shorter and easier to read, and so on. It gets more ambiguous when the consumer function performs multiple actions, e.g.:</p><p>```go func PostSomething(store interface{ identity.SessionReader catalog.ItemReader execution.JobCreator }) HttpHandlerFunc { return func(req Request) { // Use store } }</p><p>func PostSomething( readSession identity.ReadSessionFunc, readItem catalog.ReadItemFunc, createJob execution.CreateJobFunc, ) HttpHandlerFunc { return func(req Request) { // use individual functions } } ```</p><p>And, on the initiating side of this, assuming these are implemented by some aggregate \"store\" repository:</p><p><code>go router.Post(\"/things\", PostSomething(store)) // vs router.Post(\"/things\", PostSomething(store.ReadSession, store.ReadItem, store.CreateJob) </code></p><p>I'm sure there are lots of edge cases and reasons for one approach over the other. Idiomatic naming for a lot of small, purposeful interfaces in Go with  can get a bit wonky sometimes. What else? Which approach would you take, and why? Or something else entirely?</p>","contentLength":1969,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Supercharge Your Go Tests Using Fake HTTP Services","url":"https://tutorialedge.net/golang/testing-with-fake-http-services-in-go/","date":1745268512,"author":"/u/elliotforbes","guid":401,"unread":true,"content":"<h2>Why Testing With Fakes Is Important</h2><p>Testing is a critical part of building reliable and maintainable Go applications. When your code interacts with external HTTP services, relying on real HTTP requests during tests can lead to flaky and inconsistent results. Network issues, rate limits, or changes in external APIs can all cause your tests to fail unpredictably. By using fake HTTP services, you can simulate real-world scenarios in a controlled environment, ensuring your tests are fast, reliable, and repeatable. In this article, we’ll explore how to set up fake HTTP services in Go to improve the confidence you have in your systems and streamline your testing process.</p><h2>Configurable HTTP Clients with Environment Variables</h2><p>In order for this approach to work however, you do need to ensure that you build your systems in such a way that it’s easy to specify where the clients are ultimately sending your HTTP requests to. One effective approach is to use environment variables to configure the base URLs your clients interact with. This ensures that your application can seamlessly switch between production, staging, and testing environments without requiring code changes.</p><p>Another approach is to have a sensible default base URL specified as a constant within the client code. You could then leverage something like the <a href=\"https://tutorialedge.net/golang/functional-options-parameter-pattern-in-go/\" title=\"functional options parameter pattern\" target=\"_blank\" rel=\"nofollow noopener\">\n  functional options parameter pattern</a> to allow for the overriding of this value.</p><p>The important thing is that you have some level of control over this value within your client. This allows you to leverage the concept of fakes far easier in your test fixtures.</p><p>Here’s an example of how you can achieve this:</p><div><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></div><h3>Benefits of This Approach</h3><ol><li><strong>Environment-Specific Configuration</strong>: By using environment variables, you can easily configure your application to use different base URLs for production, staging, or local testing environments.</li><li>: During testing, you can set the  to point to a fake HTTP service or mock server, allowing you to simulate various scenarios without relying on external services.</li><li>: Sensitive URLs or credentials can be managed securely using environment variables, reducing the risk of hardcoding them into your source code.</li></ol><p>When writing tests, you can override the  environment variable to point to your fake HTTP service:</p><div><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></div><p>By designing your HTTP clients with configurability in mind, you can ensure that your application is both flexible and testable, leading to more robust and maintainable code.</p><h2>Writing HTTP Tests Using </h2><p>Now, traditionally, a Go developer would lean on the <a href=\"https://pkg.go.dev/net/http/httptest\" title=\"net/http/httptest\" target=\"_blank\" rel=\"nofollow noopener\">\n  net/http/httptest</a> package for creating and managing test HTTP servers. These servers allow you to simulate HTTP responses and test how your application interacts with external services in a controlled environment.</p><h3>Example: How to test Go Clients with httptest</h3><p>Suppose you have an HTTP client that fetches data from an external API. You can use  to simulate the API’s behavior and test your client’s functionality.</p><div><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></div><p>Whilst this approach works, I think it could be improved upon to provide a better experience for developers maintaining and extending these tests.</p><p>Over the past year, I’ve been working through improving the developer experience of writing a suite of fairly comprehensive and complex acceptance tests that exercise the integrations.</p><div><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></div><p>From my totally un-biased perspective, this strikes me as a far easier setup of a fake that allows me to really focus my attention on the logic contained within my clients as opposed to worry too much about the fake setup itself.</p><p>Let’s throw this into our earlier example to see how this plays out:</p><div><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></div><p>This sets up a series of sensible defaults that you’d typically expect of an API, like setting the  to . It also does some basic assertions that these endpoints defined on the fake have actually been called at least once.</p><p>For those of you that require a stronger suite of assertions on both how your client methods handle the responses, as well as guaranteeing that you’ve sent the correct request shape to the downstream API. You can take advantage of the  field when registering an  struct on the downstream API.</p><div><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></div><blockquote><p>As a general rule, I’d highly recommend fleshing out assertions that validate you are indeed sending the right shape of data that a downstream API expects. Perhaps validating the headers being sent with the request may be a good idea.</p></blockquote><h2>Simulating Errors in your Fakes</h2><p>It’d be lovely if we only ever had to worry about happy-path testing and could disregard any potential error cases or sad paths. Our software systems would be much simpler and take far less time to build. However, as we live in the real world, we know that this isn’t the case and our jobs as engineers is to ensure we’re able to handle the inevitable failures.</p><p>It’s important that regardless of what testing approach you leverage, you should be writing tests that ensure you are indeed exercising these sad-path cases.</p><p>The fakes package enables us to simulate failure cases within our tests with ease:</p><div><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></div><p>Now, when our test goes to hit our downstream API, it’ll be greeted with a lovely 404 status code and an error message that will allow us to exercise our code’s ability to handle failure gracefully.</p><p>In this article, we’ve explored how to set up tests for Go applications using fake HTTP services, leveraging both the  package and the  library. By adopting these techniques, you can create robust, reliable, and maintainable tests that simulate real-world scenarios while avoiding the pitfalls of flaky external dependencies.</p><p>The  library, in particular, aims to simplify the process of creating and managing fake HTTP services, providing a more developer-friendly experience. Whether you’re testing happy paths or simulating error cases, this library can help streamline your testing workflow and improve the overall quality of your codebase.</p><p>If you found this article helpful or have feedback on the  library, I’d love to hear from you! Feel free to reach out or contribute to the project on <a href=\"https://github.com/elliotforbes/fakes\" title=\"GitHub\" target=\"_blank\" rel=\"nofollow noopener\">\n  GitHub</a>. Your input is invaluable in making this tool even better for the Go community.</p>","contentLength":6036,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1k4o8h1/supercharge_your_go_tests_using_fake_http_services/"},{"title":"Task v3.43 is released! 🤩","url":"https://github.com/go-task/task/releases/tag/v3.43.1","date":1745256486,"author":"/u/andrey-nering","guid":404,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1k4j71h/task_v343_is_released/"},{"title":"Is there a task queuing go lib that does not depend on redis?","url":"https://www.reddit.com/r/golang/comments/1k4e23g/is_there_a_task_queuing_go_lib_that_does_not/","date":1745243570,"author":"/u/kool_psrcy","guid":403,"unread":true,"content":"<div><p>I'm wondering why all the queue related implementations are tightly coupled with redis here. I may be wrong.</p></div>   submitted by   <a href=\"https://www.reddit.com/user/kool_psrcy\"> /u/kool_psrcy </a>","contentLength":141,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Sesh - Simple persistent session store for Go, powered by BadgerDB","url":"https://www.reddit.com/r/golang/comments/1k49e12/sesh_simple_persistent_session_store_for_go/","date":1745227786,"author":"/u/pthread_mutex_t","guid":399,"unread":true,"content":"<p>I built <a href=\"https://github.com/dimmerz92/sesh\">Sesh</a>, a really simple session store which uses BadgerDB.</p><p>Key features: - In memory or persistence - Confirgurable outside of defaults - Cookie and context helpers/middleware to streamline workflows</p><p>Basically, I just wanted to understand a bit better how session cookies work and how to abstract away a lot of it. I also wanted something that was simple to undertake and understand.</p><p>It's probably no gorilla sessions but it works for my use case, so I thought I'd share it in case it's useful for anyone else.</p><p>Feel free to open issues and for features, bugs, docs, etc. Always looking for opportunities to improve myself!</p>","contentLength":624,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["dev","reddit","go"]}